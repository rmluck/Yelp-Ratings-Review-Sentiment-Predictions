{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f060f643",
   "metadata": {},
   "source": [
    "## Bayesian Model\n",
    "\n",
    "This notebook implements the Bayesian model using Pyro and fitting it with the filtered data containing averages for sentiment scores and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "249ce920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import pyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer.autoguide import AutoNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43812060",
   "metadata": {},
   "source": [
    "Load the filtered dataset from (``ca_restaurants_bayesian_dataset.csv``) and extract the features and target using Torch Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "406565c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"ca_restaurants_bayesian_dataset.csv\")\n",
    "\n",
    "# Extract the features and target\n",
    "X_sentiment = torch.tensor(df[\"avg_sentiment_score\"].values, dtype=torch.float32)\n",
    "X_log_reviews = torch.tensor(df[\"log_review_count\"].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[\"avg_rating\"].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019b67c",
   "metadata": {},
   "source": [
    "Define the Bayesian model in Pyro.\n",
    "\n",
    "- Bayesian linear regression:\n",
    "$r_d \\sim \\mathcal{N}\\left( \\alpha + \\beta_s \\cdot s_d + \\beta_r \\cdot \\log(1 + \\text{review\\_count}_d), \\sigma^2 \\right)$\n",
    "- $\\alpha$ = overall mean rating\n",
    "- $\\beta_s$ = impact of sentiment on star rating\n",
    "- $\\beta_r$ = impact of log-popularity (more reviews ---> more reliable rating)\n",
    "\n",
    "##### Priors\n",
    "- $\\alpha, \\beta_s, \\beta_r \\sim \\mathcal{N}\\left(0,1\\right)$\n",
    "- $ \\sigma \\sim HalfCauchy\\left(1\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81956082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bayesian model\n",
    "def bayesian_model(X_sentiment, X_log_reviews, y=None):\n",
    "    # Define priors for the model parameters\n",
    "    alpha = pyro.sample(\"alpha\", dist.Normal(0., 1. ))\n",
    "    beta_sentiment = pyro.sample(\"beta_sentiment\", dist.Normal(0., 1.))\n",
    "    beta_log_reviews = pyro.sample(\"beta_reviews\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfCauchy(1.))\n",
    "\n",
    "    # Define the linear model\n",
    "    mean = alpha + beta_sentiment * X_sentiment + beta_log_reviews * X_log_reviews\n",
    "    # Sample from the likelihood\n",
    "    with pyro.plate(\"data\", len(X_sentiment)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c9925",
   "metadata": {},
   "source": [
    "Define the guide (mean-field variational inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f2a19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the guide for mean-field variational inference\n",
    "guide = AutoNormal(bayesian_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14ec3a",
   "metadata": {},
   "source": [
    "Fit the model with stochastic variational inference. Train the model with 5000 steps and print the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f8abe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 : loss = 6428.512166008353\n",
      "Step 500 : loss = 551.7367859482765\n",
      "Step 1000 : loss = 197.11374771595\n",
      "Step 1500 : loss = 85.43491965532303\n",
      "Step 2000 : loss = 86.06524235010147\n",
      "Step 2500 : loss = 83.23494756221771\n",
      "Step 3000 : loss = 82.20709455013275\n",
      "Step 3500 : loss = 83.53672397136688\n",
      "Step 4000 : loss = 83.73305231332779\n",
      "Step 4500 : loss = 89.42959153652191\n"
     ]
    }
   ],
   "source": [
    "# Clear the parameter store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Define the Stochastic Variational Inference (SVI) object\n",
    "svi = SVI(\n",
    "    model=bayesian_model,\n",
    "    guide=guide,\n",
    "    optim=Adam({\"lr\": 0.01}),\n",
    "    loss=Trace_ELBO()\n",
    ")\n",
    "\n",
    "# Training the model with 5000 steps\n",
    "num_steps = 5000\n",
    "for step in range(num_steps):\n",
    "    # Perform a single step of optimization\n",
    "    loss = svi.step(X_sentiment, X_log_reviews, y)\n",
    "    # Print the loss every 500 steps\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step} : loss = {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ff89c",
   "metadata": {},
   "source": [
    "Extract posterior samples (mean and 95% credible intervals) and report estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a776f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: mean = 1.950, 95% confidence interval = (np.float32(1.9319592), np.float32(1.9692227))\n",
      "beta_sentiment: mean = 3.032, 95% confidence interval = (np.float32(3.003604), np.float32(3.0629349))\n",
      "beta_reviews: mean = -0.024, 95% confidence interval = (np.float32(-0.028452465), np.float32(-0.020107083))\n",
      "sigma: mean = 0.263, 95% confidence interval = (np.float32(0.24925363), np.float32(0.27711612))\n"
     ]
    }
   ],
   "source": [
    "# Extract the learned parameters\n",
    "predictive = Predictive(\n",
    "    bayesian_model,\n",
    "    guide=guide,\n",
    "    num_samples=1000,\n",
    "    return_sites=[\"alpha\", \"beta_sentiment\", \"beta_reviews\", \"sigma\"]\n",
    ")\n",
    "\n",
    "# Generate samples from the posterior predictive distribution\n",
    "samples = predictive(X_sentiment, X_log_reviews)\n",
    "\n",
    "for parameter in [\"alpha\", \"beta_sentiment\", \"beta_reviews\", \"sigma\"]:\n",
    "    values = samples[parameter].detach().numpy()\n",
    "    mean = values.mean()\n",
    "    confidence_interval = (np.percentile(values, 2.5), np.percentile(values, 97.5))\n",
    "    print(f\"{parameter}: mean = {mean:.3f}, 95% confidence interval = {confidence_interval}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
